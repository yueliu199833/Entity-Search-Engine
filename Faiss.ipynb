{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1092f72-24c8-43c2-b6c7-d5439f9d4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss \n",
    "#conda install -c pytorch faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014191b7-c261-4b0f-a3dc-683583184409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a7167c-e9d2-49df-8593-815d89d95358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "resp = requests.get('https://www.sec.gov/files/company_tickers.json')\n",
    "#df= pd.read_json(resp.text)\n",
    "df = pd.read_json(resp.text, orient ='index')\n",
    "\n",
    "# preprocessing data\n",
    "df0 = df.copy()\n",
    "df0['title'] = df0['title'].apply(str.lower)\n",
    "df0['title'] = df0['title'].replace('&', 'and')\n",
    "df0['title'] = df0['title'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))\n",
    "df0['title'] = df0['title'].apply(lambda x: re.sub(\"\\s\\s+\", \" \", x))\n",
    "df0['title'] = df0['title'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62da5ebe-5121-43c6-b489-dec2bc6068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "companies = set(df0[\"title\"].values.tolist())\n",
    "companies = list(companies)\n",
    "company_tokens = [set(word for word in word_tokenize(company)) for company in companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01695f6-8894-4f3a-bca6-9870fc9b9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute character n-gram embeddings\n",
    "def char_ngram_embeddings(names, n=3, dim=100):\n",
    "    char_ngrams = set()\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n + 1):\n",
    "            char_ngrams.add(name[i:i+n])\n",
    "    char_ngram_dict = {ngram: i for i, ngram in enumerate(char_ngrams)}\n",
    "    embeddings = np.zeros((len(names), len(char_ngrams), dim))\n",
    "    for i, name in enumerate(names):\n",
    "        for j in range(len(name) - n + 1):\n",
    "            ngram = name[j:j+n]\n",
    "            if ngram in char_ngram_dict:\n",
    "                embeddings[i, char_ngram_dict[ngram]] += np.random.randn(dim)\n",
    "    return embeddings\n",
    "\n",
    "# Compute character n-gram embeddings for company names\n",
    "embeddings = char_ngram_embeddings(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb39614-1613-455f-92ea-32f60089be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Faiss index\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings.astype(np.float32))\n",
    "# 就是ta卡！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad8fbe-aed9-47fa-b86c-a5dacdcc0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform similarity search\n",
    "def search(query, companies, index, k=10):\n",
    "    # Compute character n-gram embedding for query\n",
    "    query_embedding = char_ngram_embeddings([query])[0]\n",
    "    # Search Faiss index\n",
    "    distances, indices = index.search(query_embedding.astype(np.float32), k)\n",
    "    # Return top-k matching company names\n",
    "    return [companies[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f604d5-6c61-45eb-a580-fa8856e3d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test similarity search on example query\n",
    "query = 'Google'\n",
    "matches = search(query, companies, index, k=5)\n",
    "print(f\"Top matches for '{query}':\")\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
